# Тренировки по Machine Learning
### Young&&Yandex и girafe-ai
#### Осень 2023

Теоретические и практические материалы [тренировок по машинному обучению](https://yandex.ru/yaintern/training/ml-training).


| Дата | Тема и запись | Слайды и доп. материалы | Домашнее задание | Тест для самопроверки |
|:------:|:------------------------------------|:-----------------------:|:-----------------------:|:----------------------:|
| 02.11.2023 | <details><summary>[01. Введение, kNN, Naive Bayes](https://www.youtube.com/live/k3UJOG-DKHE)</summary><br>1. Задачи машинного обучения в очевидных и неочевидных местах<br>2. Основные понятия в машинном обучении<br>3. Формальная постановка задачи обучения с учителем<br>4. Метод k ближайших соседей; kNN<br>5. Правдоподобие<br>6. Наивный байесовский классификатор</details> | [Лекция №1](./step01_intro/README.md) | | |
| 03.11.2023 | <details><summary>[02. Линейная регрессия и регуляризация](https://www.youtube.com/watch?v=5qLVUO0q644)</summary><br>1. Постановка задачи регрессии<br>2. Аналитическое решение линейной регрессии<br>3. Неустойчивость решения<br>4. Теорема Гаусса-Маркова<br> 5. L1 и L2 регуляризация</details> | [Лекция №2](./step02_linear_regression/README.md) | [01. Расстояния в kNN](./homeworks/assignment01_knn/)<br>[02. Распределение Лапласа](./homeworks/assignment02_laplace/) | |
| 09.11.2023 | <details><summary>[03. Линейная классификация. Метод максимального правдоподобия](https://www.youtube.com/watch?v=R1ccYYpEpiA)</summary><br>1. Линейные механизмы классификации. Отступ.<br>2. Логистическая функция потерь. <br>3. Логистическая регрессия и бернуллиевская случайная величина.<br>4. Оценка качества классификации</details> | [Лекция №3](./step03_logistic_regression/README.md) | | |
| 10.11.2023 | <details><summary>[04. Решающие деревья, композиции деревьев, Random Forest](https://youtube.com/live/rBIVch1h5qc)</summary><br>1. Процедура построения деревьев регрессии и классификации. Жадный алгоритм.<br>2. Информационные критерии.<br>3. Бутстрап, бэггинг. «Мудрость толпы». Случайный лес.<br>4. Особые свойства решающих деревьев.</details> | [Лекция №4](./step04_trees_and_forests/README.md) | [03. Векторные производные](./homeworks/assignment03_derivatives/)<br>[04. Степенной метод](./homeworks/assignment04_power_iteration/) | |
| 15.11.2023 | <details><summary>[05. Градиентный бустинг]()</summary><br></details> | [Лекция №5](./step05_gradient_boosting/README.md) |  | |
| 17.11.2023 | <details><summary>[06. Основы Deep Learning бустинг]()</summary><br></details> | [Лекция №6](./step06_intro_to_dl/README.md) | [05. Оценка OOB](./homeworks/assignment05_bagging_and_oob/)<br>[06. Градиентный бустинг](./homeworks/assignment06_boosting/)<br>[07. Классификация MNIST](./homeworks/assignment07_mnist_classification/) | |
| 22.11.2023 | <details><summary>[07. Интерпретация предсказаний]()</summary><br></details> | [Лекция №7](./step07_explaining_ai/README.md) |  | |
| 24.11.2023 | <details><summary>[08. Механизм дистилляции. Методы обучения с учителем.]()1. Нейронные сети и "классические" методы обучени с учителем.<br>2. Дистилляция знаний.<br>3.Подведение итогов</summary><br></details> | [Лекция №8](./step08_distillation_outro/README.md) | [08. Оценка значимости признаков](./homeworks/assignment08_importances/) | |




## Теоретический минимум по математике

Доступен в [файле](./prerequisites.md).

  

## Полезная литература:

1. [Хендбук по машинному обучению от Яндекса](https://academy.yandex.ru/dataschool/book). Чудесная книга с кратким и емким описанием основных методов машинного обучения. Доступна на русском языке.

2. Probabilistic Machine Learning: An Introduction; [English link](https://probml.github.io/pml-book/book1.html), [Русский перевод](https://dmkpress.com/catalog/computer/data/978-5-93700-119-1/). Доступна онлайн на английском языке, в печатном виде – на русском.

3. Deep Learning Book: [English link](https://www.deeplearningbook.org/). Первая часть (Part I) крайне рекомендуется к прочтению.
